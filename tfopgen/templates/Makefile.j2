# Tensorflow includes and defines
TF_CFLAGS = $(shell python -c 'import tensorflow as tf; print(" ".join(tf.sysconfig.get_compile_flags()))')
TF_LFLAGS = $(shell python -c 'import tensorflow as tf; print(" ".join(tf.sysconfig.get_link_flags()))')
TF_CUDA = $(shell python -c 'import tensorflow as tf; print(int(tf.test.is_built_with_cuda()))')

TF_FLAGS=-D_MWAITXINTRIN_H_INCLUDED -D_FORCE_INLINES -D_GLIBCXX_USE_CXX11_ABI=0

# Dependencies
DEPDIR:=.d
$(shell mkdir -p $(DEPDIR) >/dev/null)
DEPFLAGS=-MT $@ -MMD -MP -MF $(DEPDIR)/$*.Td

# Define our sources, compiling CUDA code if it's enabled
ifeq ($(TF_CUDA), 1)
    SOURCES=$(wildcard *.cpp *.cu)
else
    SOURCES=$(wildcard *.cpp)
endif

# Define objects and shared_library
OBJECTS=$(addsuffix .o, $(basename $(SOURCES)))
LIBRARY={{shared_library}}

# Compiler flags
CPPFLAGS =-std=c++11 $(TF_CFLAGS) -fPIC -fopenmp \
         -O2 -march=native -mtune=native
NVCCFLAGS =-std=c++11 -DGOOGLE_CUDA=$(TF_CUDA) $(TF_CFLAGS) $(INCLUDES) \
        -x cu --compiler-options "-fPIC" --gpu-architecture=sm_30 -lineinfo

LDFLAGS = -fPIC -fopenmp $(TF_LFLAGS)

ifeq ($(TF_CUDA), 1)
    LDFLAGS := $(LDFLAGS) -L /usr/local/cuda/lib64
    LDFLAGS := $(LDFLAGS) -lcuda -lcudart
endif

# Compiler directives
COMPILE.cpp = g++ $(DEPFLAGS) $(CPPFLAGS) -c
COMPILE.nvcc = nvcc --compiler-options " $(DEPFLAGS)" $(NVCCFLAGS) -c

all : $(LIBRARY)

%.o : %.cpp
	$(COMPILE.cpp) $<

%.o : %.cu
	$(COMPILE.nvcc) $<

clean :
	rm -f $(OBJECTS) $(LIBRARY)

$(LIBRARY) : $(OBJECTS)
	g++  -shared $(OBJECTS) -o $(LIBRARY) $(LDFLAGS)

$(DEPDIR)/%.d: ;
.PRECIOUS: $(DEPDIR)/%.d

-include $(patsubst %,$(DEPDIR)/%.d,$(basename $(SRCS)))
